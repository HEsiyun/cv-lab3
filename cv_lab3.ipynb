{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8DEOBMUHHw0FsNUishovY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HEsiyun/cv-lab3/blob/main/cv_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIkLmgrYeH7L",
        "outputId": "ccdcf1cd-ca20-4cc7-c858-016e5bbb71b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.21-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.21-py3-none-any.whl (877 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.1/877.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.21 ultralytics-thop-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNaPJZ9rPDPm",
        "outputId": "41115119-2a02-4250-e1b0-da41ff1e2119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset\n",
        "!rm -rf /content/yolov8_dataset\n",
        "!rm -rf /content/darknet\n",
        "!rm -rf /content/yolov8_finetune"
      ],
      "metadata": {
        "id": "kEDV0zN-hNKT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjUXZ7zYPGQs",
        "outputId": "5cf7953a-7810-433f-c9cb-674742aef2b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 24 03:56:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"19W45cMfvBnhV0vqBVJgUHHpe7WC1YLdG\"\n",
        "url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(url, \"/content/dataset.zip\", quiet=False)"
      ],
      "metadata": {
        "id": "ONbRRssRYdqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "95eedfef-a20a-4455-c8b5-dc9e517d62fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=19W45cMfvBnhV0vqBVJgUHHpe7WC1YLdG\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=19W45cMfvBnhV0vqBVJgUHHpe7WC1YLdG&confirm=t&uuid=83fe5ddb-8c01-4abc-8f6e-e840542cf6ad\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 211M/211M [00:02<00:00, 93.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the zip file\n",
        "try:\n",
        "    with zipfile.ZipFile(\"/content/dataset.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/dataset\")\n",
        "    print(\"Dataset downloaded and unzipped successfully.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: The downloaded file is not a valid zip file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKtlmkAAid7h",
        "outputId": "c1b9472c-048e-4f59-efa7-1df0012f45fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths to your dataset\n",
        "images_dir = '/content/dataset/filtered_images'  # Adjust this path as necessary\n",
        "annotations_dir = '/content/dataset/filtered_annotations'  # Adjust this path as necessary\n",
        "\n",
        "# Output directory for YOLOv8 training data\n",
        "output_dir = '/content/yolov8_dataset'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Create directories for train, val, and test\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'val')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of image files\n",
        "image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_files, temp_files = train_test_split(image_files, test_size=0.3, random_state=42)  # 70% train\n",
        "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)  # 15% val, 15% test\n",
        "\n",
        "# Function to convert XML annotations to YOLO format and save as .txt\n",
        "def convert_xml_to_yolo(xml_file, img_width, img_height):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    yolo_lines = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        # Convert class name to an index (You may want to create a mapping)\n",
        "        class_id = 0\n",
        "\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = float(bndbox.find('xmin').text)\n",
        "        ymin = float(bndbox.find('ymin').text)\n",
        "        xmax = float(bndbox.find('xmax').text)\n",
        "        ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format (normalized coordinates)\n",
        "        x_center = (xmin + xmax) / 2 / img_width\n",
        "        y_center = (ymin + ymax) / 2 / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        yolo_lines.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    return yolo_lines\n",
        "\n",
        "# Function to copy images and corresponding annotations\n",
        "def copy_files_and_convert_labels(file_list, source_dir, dest_dir, annotation_dir):\n",
        "    for filename in file_list:\n",
        "        # Copy image files\n",
        "        src_img_path = os.path.join(source_dir, filename)\n",
        "        dest_img_path = os.path.join(dest_dir, filename)\n",
        "        shutil.copy(src_img_path, dest_img_path)\n",
        "\n",
        "        # Get image dimensions\n",
        "        img_width, img_height = 600, 600  # You can modify this based on your actual image size\n",
        "\n",
        "        # Convert and save corresponding annotation files\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        src_label_path = os.path.join(annotation_dir, base_name + '.xml')\n",
        "        if os.path.exists(src_label_path):\n",
        "            yolo_lines = convert_xml_to_yolo(src_label_path, img_width, img_height)\n",
        "            dest_label_path = os.path.join(dest_dir, base_name + '.txt')\n",
        "            with open(dest_label_path, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_lines))\n",
        "\n",
        "# Copy files to their respective directories and convert labels\n",
        "copy_files_and_convert_labels(train_files, images_dir, train_dir, annotations_dir)\n",
        "copy_files_and_convert_labels(val_files, images_dir, val_dir, annotations_dir)\n",
        "copy_files_and_convert_labels(test_files, images_dir, test_dir, annotations_dir)\n",
        "\n",
        "print(\"Dataset organized and annotations converted to YOLO format:\")\n",
        "print(f\"- Train images: {len(train_files)}\")\n",
        "print(f\"- Validation images: {len(val_files)}\")\n",
        "print(f\"- Test images: {len(test_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQiDx724bAM8",
        "outputId": "f654cfdf-b7f5-4799-c880-ee1eeaae1a5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized and annotations converted to YOLO format:\n",
            "- Train images: 2993\n",
            "- Validation images: 642\n",
            "- Test images: 642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the base directory where your dataset is located\n",
        "base_dir = \"/content/yolov8_dataset\"\n",
        "\n",
        "# Define the paths for train, val, and test directories\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# Define the class names\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Define the path to the annotations directory\n",
        "annotations_dir = '/content/dataset/filtered_annotations'\n",
        "\n",
        "# Convert the set to a sorted list\n",
        "class_names = [0]\n",
        "\n",
        "# Create the data.yaml content\n",
        "data_yaml_content = f\"\"\"\n",
        "# YOLOv8 data configuration file\n",
        "\n",
        "# Base directory of the dataset\n",
        "path: {base_dir}\n",
        "\n",
        "# Paths for training, validation, and testing image directories\n",
        "train: {train_dir}\n",
        "val: {val_dir}\n",
        "test: {test_dir}\n",
        "\n",
        "# Number of classes\n",
        "nc: {len(class_names)}\n",
        "\n",
        "# Class names\n",
        "names:\n",
        "\"\"\"\n",
        "\n",
        "# Add class names to the YAML content\n",
        "for i, name in enumerate(class_names):\n",
        "    data_yaml_content += f\"  {i}: '{name}'\\n\"\n",
        "\n",
        "# Write the content to data.yaml\n",
        "data_yaml_path = os.path.join('/content/yolov8_dataset', \"data.yaml\")\n",
        "with open(data_yaml_path, \"w\") as file:\n",
        "    file.write(data_yaml_content)\n",
        "\n",
        "print(\"data.yaml file has been created successfully at:\", data_yaml_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHXdm8M3fXKQ",
        "outputId": "cb60fa5b-6d17-4a9c-c190-412a39730288"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml file has been created successfully at: /content/yolov8_dataset/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: fine-tune last layer of the train dataset for 3 epochs with 1 warmup, output performance on val in each epoch\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Define the path to the data.yaml file\n",
        "data_yaml_path = '/content/yolov8_dataset/data.yaml'\n",
        "\n",
        "# Fine-tune the model on the custom dataset\n",
        "results = model.train(\n",
        "    data=data_yaml_path,          # Path to your dataset configuration (data.yaml)\n",
        "    epochs=30,                    # Increased number of epochs for fine-tuning\n",
        "    imgsz=640,                    # Image size for training\n",
        "    patience=10,                  # Early stopping patience (if no improvement after 10 epochs)\n",
        "    device=[0],                   # Specify the device (e.g., GPU 0)\n",
        "    optimizer='Adam',             # Using Adam optimizer for training\n",
        "    lr0=0.0001,                   # Lower initial learning rate for fine-tuning\n",
        "    lrf=0.01,                     # Final learning rate (after warm-up)\n",
        "    warmup_epochs=2,              # Warm-up for 2 epochs (to avoid abrupt changes in gradients)\n",
        "    freeze=[0, 1, 2, 3],          # Freezing all layers except the last layer (adjust if needed)\n",
        "    project='/content/yolov8_finetune'  # Path to save the fine-tuning project results\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2LiF-P_CjcLA",
        "outputId": "b2ebd84f-275c-4d93-de8e-4904a9f13176"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'\u001b[31m\u001b[1mlog\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-c7baa145-0bdb-4130-a6f6-79b175b81678.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'obb', 'detect', 'classify', 'pose', 'segment'}\n                MODE (required) is one of {'predict', 'track', 'train', 'export', 'val', 'benchmark'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n    \n    5. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-10-06c4ee552c2c>\"\u001b[0m, line \u001b[1;32m12\u001b[0m, in \u001b[1;35m<cell line: 12>\u001b[0m\n    results = model.train(\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\"\u001b[0m, line \u001b[1;32m796\u001b[0m, in \u001b[1;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\"\u001b[0m, line \u001b[1;32m101\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0m, line \u001b[1;32m251\u001b[0m, in \u001b[1;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0;36m, line \u001b[0;32m436\u001b[0;36m, in \u001b[0;35mcheck_dict_alignment\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mlog\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-c7baa145-0bdb-4130-a6f6-79b175b81678.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'obb', 'detect', 'classify', 'pose', 'segment'}\n                MODE (required) is one of {'predict', 'track', 'train', 'export', 'val', 'benchmark'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n    \n    5. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the best model from the training run\n",
        "best_model = YOLO('/content/yolov8_finetune/train/weights/best.pt')\n",
        "\n",
        "# Run inference on the test dataset\n",
        "results = best_model.val(data='/content/yolov8_dataset/data.yaml')\n",
        "\n",
        "# Print essential results\n",
        "print(\"Validation Results:\")\n",
        "print(f\" - mAP: {results.box.map.mean():.4f}\")  # Mean Average Precision\n",
        "print(f\" - AP50: {results.box.ap50.mean():.4f}\")  # Average Precision at IoU=0.50\n",
        "print(f\" - Precision: {results.box.p.mean():.4f}\")  # Precision\n",
        "print(f\" - Recall: {results.box.r.mean():.4f}\")  # Recall"
      ],
      "metadata": {
        "id": "9VatFDT2a02Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "7b1df1d7-cd1d-45aa-9044-f75c0813c3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'YOLO' object has no attribute 'test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-383749ead051>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Run inference on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov8_dataset/data.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print essential results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'YOLO' object has no attribute 'test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gF8QZCGDpB4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}