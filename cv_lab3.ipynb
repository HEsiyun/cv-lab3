{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYrYUQrDb/+v7rd5j+k/Gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46f6c7952f9c4832bf3f3c7eb86defce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_378eaa89cd7e4717a445a31076b3476b",
              "IPY_MODEL_c6a28a2fcf414b888b15a0f5eb44c66e"
            ],
            "layout": "IPY_MODEL_4949fb6345c2462393ae917e032dd383"
          }
        },
        "378eaa89cd7e4717a445a31076b3476b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d1f05dba4a47b396069c82918b6ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_9f56418cb6a744d28b26c161a77afa15",
            "value": "13.743 MB of 13.743 MB uploaded\r"
          }
        },
        "c6a28a2fcf414b888b15a0f5eb44c66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f3e52b26764a8fb44f68ee2a0f20a3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_130a321603444b5d95901c1ba82ce646",
            "value": 1
          }
        },
        "4949fb6345c2462393ae917e032dd383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d1f05dba4a47b396069c82918b6ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f56418cb6a744d28b26c161a77afa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41f3e52b26764a8fb44f68ee2a0f20a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130a321603444b5d95901c1ba82ce646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HEsiyun/cv-lab3/blob/main/cv_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIkLmgrYeH7L",
        "outputId": "fe768e5d-cfc9-41e3-fac8-52918cb21f1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.21)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNaPJZ9rPDPm",
        "outputId": "2fef394d-ad48-4a2f-ca8e-a3c09edad13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset\n",
        "!rm -rf /content/yolov8_dataset\n",
        "!rm -rf /content/darknet\n",
        "!rm -rf /content/yolov8_finetune"
      ],
      "metadata": {
        "id": "kEDV0zN-hNKT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjUXZ7zYPGQs",
        "outputId": "d6d8f096-3c5d-4d4f-c0b4-b1f984ebfe32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 24 03:15:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"19W45cMfvBnhV0vqBVJgUHHpe7WC1YLdG\"\n",
        "url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(url, \"/content/dataset.zip\", quiet=False)"
      ],
      "metadata": {
        "id": "ONbRRssRYdqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the zip file\n",
        "try:\n",
        "    with zipfile.ZipFile(\"/content/dataset.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/dataset\")\n",
        "    print(\"Dataset downloaded and unzipped successfully.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"Error: The downloaded file is not a valid zip file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKtlmkAAid7h",
        "outputId": "8533b947-10bc-4c9c-893b-d068152fa6f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths to your dataset\n",
        "images_dir = '/content/dataset/filtered_images'  # Adjust this path as necessary\n",
        "annotations_dir = '/content/dataset/filtered_annotations'  # Adjust this path as necessary\n",
        "\n",
        "# Output directory for YOLOv8 training data\n",
        "output_dir = '/content/yolov8_dataset'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Create directories for train, val, and test\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'val')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of image files\n",
        "image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_files, temp_files = train_test_split(image_files, test_size=0.3, random_state=42)  # 70% train\n",
        "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)  # 15% val, 15% test\n",
        "\n",
        "# Function to convert XML annotations to YOLO format and save as .txt\n",
        "def convert_xml_to_yolo(xml_file, img_width, img_height):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    yolo_lines = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        # Convert class name to an index (You may want to create a mapping)\n",
        "        class_id = 0\n",
        "\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = float(bndbox.find('xmin').text)\n",
        "        ymin = float(bndbox.find('ymin').text)\n",
        "        xmax = float(bndbox.find('xmax').text)\n",
        "        ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format (normalized coordinates)\n",
        "        x_center = (xmin + xmax) / 2 / img_width\n",
        "        y_center = (ymin + ymax) / 2 / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        yolo_lines.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    return yolo_lines\n",
        "\n",
        "# Function to copy images and corresponding annotations\n",
        "def copy_files_and_convert_labels(file_list, source_dir, dest_dir, annotation_dir):\n",
        "    for filename in file_list:\n",
        "        # Copy image files\n",
        "        src_img_path = os.path.join(source_dir, filename)\n",
        "        dest_img_path = os.path.join(dest_dir, filename)\n",
        "        shutil.copy(src_img_path, dest_img_path)\n",
        "\n",
        "        # Get image dimensions\n",
        "        img_width, img_height = 600, 600  # You can modify this based on your actual image size\n",
        "\n",
        "        # Convert and save corresponding annotation files\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        src_label_path = os.path.join(annotation_dir, base_name + '.xml')\n",
        "        if os.path.exists(src_label_path):\n",
        "            yolo_lines = convert_xml_to_yolo(src_label_path, img_width, img_height)\n",
        "            dest_label_path = os.path.join(dest_dir, base_name + '.txt')\n",
        "            with open(dest_label_path, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_lines))\n",
        "\n",
        "# Copy files to their respective directories and convert labels\n",
        "copy_files_and_convert_labels(train_files, images_dir, train_dir, annotations_dir)\n",
        "copy_files_and_convert_labels(val_files, images_dir, val_dir, annotations_dir)\n",
        "copy_files_and_convert_labels(test_files, images_dir, test_dir, annotations_dir)\n",
        "\n",
        "print(\"Dataset organized and annotations converted to YOLO format:\")\n",
        "print(f\"- Train images: {len(train_files)}\")\n",
        "print(f\"- Validation images: {len(val_files)}\")\n",
        "print(f\"- Test images: {len(test_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQiDx724bAM8",
        "outputId": "951d152d-8401-42ef-93ab-3cd713975d13"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized and annotations converted to YOLO format:\n",
            "- Train images: 2993\n",
            "- Validation images: 642\n",
            "- Test images: 642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the base directory where your dataset is located\n",
        "base_dir = \"/content/yolov8_dataset\"\n",
        "\n",
        "# Define the paths for train, val, and test directories\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# Define the class names\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Define the path to the annotations directory\n",
        "annotations_dir = '/content/dataset/filtered_annotations'\n",
        "\n",
        "# Convert the set to a sorted list\n",
        "class_names = [0]\n",
        "\n",
        "# Create the data.yaml content\n",
        "data_yaml_content = f\"\"\"\n",
        "# YOLOv8 data configuration file\n",
        "\n",
        "# Base directory of the dataset\n",
        "path: {base_dir}\n",
        "\n",
        "# Paths for training, validation, and testing image directories\n",
        "train: {train_dir}\n",
        "val: {val_dir}\n",
        "test: {test_dir}\n",
        "\n",
        "# Number of classes\n",
        "nc: {len(class_names)}\n",
        "\n",
        "# Class names\n",
        "names:\n",
        "\"\"\"\n",
        "\n",
        "# Add class names to the YAML content\n",
        "for i, name in enumerate(class_names):\n",
        "    data_yaml_content += f\"  {i}: '{name}'\\n\"\n",
        "\n",
        "# Write the content to data.yaml\n",
        "data_yaml_path = os.path.join('/content/yolov8_dataset', \"data.yaml\")\n",
        "with open(data_yaml_path, \"w\") as file:\n",
        "    file.write(data_yaml_content)\n",
        "\n",
        "print(\"data.yaml file has been created successfully at:\", data_yaml_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHXdm8M3fXKQ",
        "outputId": "c18f8b7e-b5d2-4aa9-c933-d451ab044866"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml file has been created successfully at: /content/yolov8_dataset/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: fine-tune last layer of the train dataset for 3 epochs with 1 warmup, output performance on val in each epoch\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Define the path to your data.yaml file\n",
        "data_yaml_path = '/content/yolov8_dataset/data.yaml'\n",
        "\n",
        "# Fine-tune the model on your custom dataset\n",
        "results = model.train(data=data_yaml_path, epochs=3, imgsz=640, patience=20, device=[0], optimizer='Adam', lr0=0.001, lrf=0.01,\n",
        "                     warmup_epochs=1,\n",
        "                     project='/content/yolov8_finetune')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "46f6c7952f9c4832bf3f3c7eb86defce",
            "378eaa89cd7e4717a445a31076b3476b",
            "c6a28a2fcf414b888b15a0f5eb44c66e",
            "4949fb6345c2462393ae917e032dd383",
            "71d1f05dba4a47b396069c82918b6ae6",
            "9f56418cb6a744d28b26c161a77afa15",
            "41f3e52b26764a8fb44f68ee2a0f20a3",
            "130a321603444b5d95901c1ba82ce646"
          ]
        },
        "id": "2LiF-P_CjcLA",
        "outputId": "0d64fd64-5b12-4938-83c3-329ca3c92969"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.21 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/yolov8_dataset/data.yaml, epochs=3, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=[0], workers=8, project=/content/yolov8_finetune, name=train, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=1, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/yolov8_finetune/train\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov8_finetune/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov8_dataset/train.cache... 2993 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2993/2993 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov8_dataset/val.cache... 642 images, 0 backgrounds, 0 corrupt: 100%|██████████| 642/642 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/yolov8_finetune/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov8_finetune/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      2.52G      1.003      1.427       1.21          5        640: 100%|██████████| 188/188 [01:08<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  57%|█████▋    | 12/21 [00:06<00:04,  1.88it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 21/21 [00:09<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        642       2065      0.921      0.706      0.752      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      2.22G     0.9589      1.215      1.206         82        640:  10%|▉         | 18/188 [00:05<00:52,  3.24it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "        2/3      2.26G     0.9041      1.082      1.169          3        640: 100%|██████████| 188/188 [01:18<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  81%|████████  | 17/21 [00:06<00:01,  3.60it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 21/21 [00:07<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        642       2065      0.959      0.724      0.787        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3      2.21G     0.8159     0.9666      1.124         89        640:  12%|█▏        | 23/188 [00:08<01:14,  2.21it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "        3/3      2.26G     0.8267     0.9626      1.135          3        640: 100%|██████████| 188/188 [01:16<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 21/21 [00:06<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        642       2065      0.979      0.734      0.806      0.736\n",
            "\n",
            "3 epochs completed in 0.071 hours.\n",
            "Optimizer stripped from /content/yolov8_finetune/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolov8_finetune/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolov8_finetune/train/weights/best.pt...\n",
            "Ultralytics 8.3.21 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 21/21 [00:13<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        642       2065      0.979      0.734      0.806      0.736\n",
            "Speed: 0.5ms preprocess, 3.0ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolov8_finetune/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='9.351 MB of 13.741 MB uploaded\\r'), FloatProgress(value=0.6804781204424674, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46f6c7952f9c4832bf3f3c7eb86defce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█▅▁</td></tr><tr><td>lr/pg1</td><td>▁█▁</td></tr><tr><td>lr/pg2</td><td>▁█▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▁█</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▁█</td></tr><tr><td>metrics/precision(B)</td><td>▁▁█</td></tr><tr><td>metrics/recall(B)</td><td>▁▁█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▁▁█</td></tr><tr><td>train/cls_loss</td><td>█▁▂</td></tr><tr><td>train/dfl_loss</td><td>▁▁█</td></tr><tr><td>val/box_loss</td><td>▁▁█</td></tr><tr><td>val/cls_loss</td><td>▁█▁</td></tr><tr><td>val/dfl_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00034</td></tr><tr><td>lr/pg1</td><td>0.00034</td></tr><tr><td>lr/pg2</td><td>0.00034</td></tr><tr><td>metrics/mAP50(B)</td><td>0.80589</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.73618</td></tr><tr><td>metrics/precision(B)</td><td>0.97871</td></tr><tr><td>metrics/recall(B)</td><td>0.73449</td></tr><tr><td>model/GFLOPs</td><td>10.513</td></tr><tr><td>model/parameters</td><td>3488550</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>4.858</td></tr><tr><td>train/box_loss</td><td>0.8267</td></tr><tr><td>train/cls_loss</td><td>0.96265</td></tr><tr><td>train/dfl_loss</td><td>1.13505</td></tr><tr><td>val/box_loss</td><td>0.59479</td></tr><tr><td>val/cls_loss</td><td>0.68562</td></tr><tr><td>val/dfl_loss</td><td>1.00281</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">last_layer_finetune3</strong> at: <a href='https://wandb.ai/hesiyun0603-no/yolov8_finetune/runs/5l9lc60e' target=\"_blank\">https://wandb.ai/hesiyun0603-no/yolov8_finetune/runs/5l9lc60e</a><br/> View project at: <a href='https://wandb.ai/hesiyun0603-no/yolov8_finetune' target=\"_blank\">https://wandb.ai/hesiyun0603-no/yolov8_finetune</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 27 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_032635-5l9lc60e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'DetMetrics' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6ee146a9f7c9>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Print performance on the validation set for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_result\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch_result.epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Metrics: {epoch_result.metrics}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DetMetrics' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the best model from the training run\n",
        "best_model = YOLO('/content/yolov8_finetune/train/weights/best.pt')\n",
        "\n",
        "# Run inference on the test dataset\n",
        "results = best_model.val(data='/content/yolov8_dataset/data.yaml')\n",
        "\n",
        "# Print essential results\n",
        "print(\"Validation Results:\")\n",
        "print(f\" - mAP: {results.box.map.mean():.4f}\")  # Mean Average Precision\n",
        "print(f\" - AP50: {results.box.ap50.mean():.4f}\")  # Average Precision at IoU=0.50\n",
        "print(f\" - Precision: {results.box.p.mean():.4f}\")  # Precision\n",
        "print(f\" - Recall: {results.box.r.mean():.4f}\")  # Recall"
      ],
      "metadata": {
        "id": "9VatFDT2a02Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "7b1df1d7-cd1d-45aa-9044-f75c0813c3a4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'YOLO' object has no attribute 'test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-383749ead051>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Run inference on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov8_dataset/data.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print essential results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'YOLO' object has no attribute 'test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gF8QZCGDpB4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}